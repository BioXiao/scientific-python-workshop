{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupvervised Learning: Clustering\n",
    "\n",
    "Clustering is a class of unsupervised learning methods that associates observations according to some specified measure of similarity (e.g. Euclidean distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Algorithm\n",
    "\n",
    "The K-means clustering algorithm associates each point $x_i$ in a set of input points $\\{x_1, x_2, \\ldots, x_m\\}$ to $K$ clusters. Each cluster is specified by a **centroid** that is the average location of all the points in the cluster. The algorithm proceeds iteratively from arbitrary centroid locations, updating the membership of each point according to minimum distance, then updating the centroid location based on the new cluster membership. \n",
    "\n",
    "In this sense, it is similar to the expectation maximization (EM) algorithm. Recall that in EM we iteratively assigned labels to observations, according to which mixture component they were most likely to have been derived from. K-means is simpler, in that we just use the minimum distance to assign membership.\n",
    "\n",
    "The algorithm will have converged when the assignment of points to centroids does not change with each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "1. Initialize cluster centroids:\n",
    "\n",
    "    $$\\mu^{(0)}_1, \\ldots, \\mu^{(0)}_k \\in \\mathbb{R}^n$$\n",
    "\n",
    "2. Iterate until converged:\n",
    "\n",
    "    a. Set $c_i = \\text{argmin}_j || x_i - \\mu_j^{(s)} ||$\n",
    "    \n",
    "    b. Update centroids:\n",
    "    \n",
    "    $$\\mu_j^{(s+1)} = \\frac{\\sum_{i=1}^m I[c_i = j] x_i}{\\sum_{i=1}^m I[c_i = j]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means algorithm is simply a Gaussian mixture model with two restrictions: \n",
    "\n",
    "1. the covariance matrix is spherical: \n",
    "\n",
    "    $$\\Sigma_k = \\sigma I_D$$\n",
    "\n",
    "2. the mixture weights are fixed:\n",
    "\n",
    "    $$\\pi_k = \\frac{1}{K}$$\n",
    "\n",
    "Hence, we are only interested in locating the appropriate centroid of the clusters. This serves to speed computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the distortion function:\n",
    "\n",
    "$$J(c,\\mu) = \\sum_{i]1}^m ||x_i - \\mu_{c_i}||$$\n",
    "\n",
    "which gets smaller at every iteration. So, k-means is coordinate ascent on $J(c,\\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing $k$\n",
    "\n",
    "To check whether a chosen $k$ is reasonable, one approach is to compare the distances between the centroids to the mean distance bewween each data point and their assigned centroid. A good fit involves relatively large inter-centroid distances. \n",
    "\n",
    "The appropriate value for k (the number of clusters) may depend on the goals of the analysis, or it may be chosen algorithmically, using an optimization procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: clustering random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = np.random.uniform(0, 10, 50).reshape(2, 25)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with $k=4$, arbitrarily assigned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = (3, 3), (3, 7), (7, 3), (7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.transpose(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.scatter(*np.transpose(centroids), c='r', marker='+', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function `cdist` from SciPy to calculate the distances from each point to each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "distances = cdist(centroids, list(zip(x,y)))\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the initial assignment to centroids by picking the minimum distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = distances.argmin(axis=0)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c=np.array(list('rgbc'))[labels])\n",
    "plt.scatter(*np.transpose(centroids), c='r', marker='+', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-assign the centroid locations based on the means of the current members' locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_centroids = [(x[labels==i].mean(), y[labels==i].mean())\n",
    "                 for i in range(len(centroids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c=np.array(list('rgbc'))[labels])\n",
    "plt.scatter(*np.transpose(new_centroids), c='r', marker='+', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we simply iterate these steps until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = new_centroids\n",
    "iterations = 20\n",
    "\n",
    "for _ in range(iterations):\n",
    "    distances = cdist(centroids, list(zip(x,y)))\n",
    "    labels = distances.argmin(axis=0)\n",
    "    centroids = [(x[labels==i].mean(), y[labels==i].mean())\n",
    "                 for i in range(len(centroids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c=np.array(list('rgbc'))[labels])\n",
    "plt.scatter(*np.transpose(centroids), c='r', marker='+', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means using `scikit-learn`\n",
    "\n",
    "The `scikit-learn` package includes a `KMeans` class for flexibly fitting K-means models. It includes additional features, such as initialization options and the ability to set the convergence tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from numpy.random import RandomState\n",
    "rng = RandomState(1)\n",
    "\n",
    "# Instantiate model\n",
    "kmeans = KMeans(n_clusters=4, random_state=rng)\n",
    "# Fit model\n",
    "kmeans.fit(np.transpose((x,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can retrieve the labels and cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting plot should look very similar to the one we fit by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c=np.array(list('rgbc'))[kmeans.labels_])\n",
    "plt.scatter(*kmeans.cluster_centers_.T, c='r', marker='+', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Microbiome data\n",
    "\n",
    "The `microbiome.csv` dataset contains counts of various microbe taxa extraced from either tissue or stool samples of NICU infants. We might be interested in seeing if samples cluster into groups approximately corresponding to location (tissue or stool) based on the counts of each bacterial taxon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "microbiome = pd.read_csv(\"../data/microbiome.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transpose the data so that it can be used with `scikit-learn`'s interface. Fortunately, Pandas makes this relatively painless. The data are stored in *long* format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "microbiome.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we need the features (*i.e.* taxa) in columns, with a row for each sample. First we drop the `Group` column, then pivot the `Taxon` column into a column index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "microbiome_pivoted.pivot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "microbiome_pivoted = microbiome.drop('Group', axis=1).pivot(index='Patient', \n",
    "                        columns='Taxon').stack(level=0).reset_index()\n",
    "microbiome_pivoted.columns.name = None\n",
    "microbiome_pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we drop the unused column and change the location variable from `str` type to `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "microbiome_data = microbiome_pivoted.drop('Patient', \n",
    "                        axis=1).rename(columns={'level_1':'Location'}\n",
    "                                       ).replace({'Tissue': 0 , 'Stool':1})\n",
    "\n",
    "y = microbiome_data.values[:, 0]\n",
    "X = microbiome_data.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "microbiome_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the analysis, and aid visualization, we will again perform a PCA to isolate the majority of the variation into two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from itertools import cycle\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "def plot_2D(data, target, target_names, pca):\n",
    "    colors = cycle('rgbcmykw')\n",
    "    target_ids = range(len(target_names))\n",
    "    plt.figure()\n",
    "    for i, c, label in zip(target_ids, colors, target_names):\n",
    "        plt.scatter(data[target == i, 0], data[target == i, 1],\n",
    "                   c=c, label=label)\n",
    "    var_explained = pca.explained_variance_ratio_ * 100\n",
    "    plt.xlabel('First Component: {0:.1f}%'.format(var_explained[0]))\n",
    "    plt.ylabel('Second Component: {0:.1f}%'.format(var_explained[1]))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_2D(X_pca, y, ['Tissue', 'Stool'], pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `KMeans` object with `k=2`, and fit the data with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km_microbiome = KMeans(n_clusters=2, random_state=rng)\n",
    "km_microbiome.fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can extract the cluster centroids (in the `cluster_center_` attribute) and the group labels (in `labels_`) in order to generate a plot of the classification result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.round(km_microbiome.cluster_centers_, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km_microbiome.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_2D(X_pca, km_microbiome.labels_, [\"c1\", \"c2\"], pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` includes a suite of well-known clustering algorithms. Like most unsupervised learning models in the scikit, they expect the data to be clustered to have the shape `(n_samples, n_features)`:\n",
    "\n",
    "- `sklearn.cluster.KMeans`\n",
    ": The simplest, yet effective clustering algorithm. Needs to be provided with the\n",
    "number of clusters in advance, and assumes that the data is normalized as input\n",
    "(but use a PCA model as preprocessor).\n",
    "- `sklearn.cluster.MeanShift`\n",
    ": Can find better looking clusters than KMeans but is not scalable to high number of samples.\n",
    "- `sklearn.cluster.DBSCAN`\n",
    ": Can detect irregularly shaped clusters based on density, i.e. sparse regions in\n",
    "the input space are likely to become inter-cluster boundaries. Can also detect\n",
    "outliers (samples that are not part of a cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: NEC\n",
    "\n",
    "If all the odd-numbered patients are healthy controls and the even-numbered patients have necrotizing enterocolitis (NEC), see if either the tissue or stool samples cluster according to group status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: clustering baseball statistics\n",
    "\n",
    "We can use clustering to try to find interesting groupings among sets of baseball statistics. Load the baseball dataset and run a clustering algorithm on the set of three statistics:\n",
    "\n",
    "* hit rate: hits / at bats\n",
    "* strikeout rate: strikeouts / at bats\n",
    "* walk rate: bases on balls /at bats\n",
    "\n",
    "You should probably set a minimum number of at bats to qualify for the analysis, since there are pitchers that get only a handful of at bats each year.\n",
    "\n",
    "Since we are clustering in 3 dimensions, you can visualize the output as a series of pairwise plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseball = pd.read_csv(\"../data/baseball.csv\", index_col=0)\n",
    "baseball.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
